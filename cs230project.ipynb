{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import mnist, cifar10, cifar100\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Data shapes (10000, 28, 28, 1) (10000, 10) (60000, 28, 28, 1) (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "# Process the data, normalize it, reshape it, and one-hot-encode the labels\n",
    "img_rows, img_cols, channels = 28, 28, 1\n",
    "num_classes = 10\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape((-1, img_rows, img_cols, channels))\n",
    "x_test = x_test.reshape((-1, img_rows, img_cols, channels))\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Data shapes\", x_test.shape, y_test.shape, x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu', input_shape=(img_rows, img_cols, channels)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0196 - accuracy: 0.8640 - val_loss: 0.0067 - val_accuracy: 0.9548\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0093 - accuracy: 0.9391 - val_loss: 0.0049 - val_accuracy: 0.9679\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0073 - accuracy: 0.9532 - val_loss: 0.0043 - val_accuracy: 0.9710\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0067 - accuracy: 0.9571 - val_loss: 0.0042 - val_accuracy: 0.9722\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0058 - accuracy: 0.9624 - val_loss: 0.0035 - val_accuracy: 0.9773\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0055 - accuracy: 0.9649 - val_loss: 0.0039 - val_accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0050 - accuracy: 0.9685 - val_loss: 0.0039 - val_accuracy: 0.9747\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0047 - accuracy: 0.9702 - val_loss: 0.0034 - val_accuracy: 0.9794\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0045 - accuracy: 0.9714 - val_loss: 0.0034 - val_accuracy: 0.9796\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0043 - accuracy: 0.9726 - val_loss: 0.0034 - val_accuracy: 0.9788\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0040 - accuracy: 0.9742 - val_loss: 0.0033 - val_accuracy: 0.9801\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0040 - accuracy: 0.9751 - val_loss: 0.0034 - val_accuracy: 0.9787\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0039 - accuracy: 0.9753 - val_loss: 0.0034 - val_accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0038 - accuracy: 0.9762 - val_loss: 0.0035 - val_accuracy: 0.9776\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0037 - accuracy: 0.9767 - val_loss: 0.0031 - val_accuracy: 0.9810\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0035 - accuracy: 0.9786 - val_loss: 0.0032 - val_accuracy: 0.9808\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0033 - accuracy: 0.9790 - val_loss: 0.0032 - val_accuracy: 0.9795\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0034 - accuracy: 0.9790 - val_loss: 0.0035 - val_accuracy: 0.9796\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0033 - accuracy: 0.9794 - val_loss: 0.0034 - val_accuracy: 0.9791\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0032 - accuracy: 0.9802 - val_loss: 0.0032 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e07c8730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy on regular images: [0.00320904771797359, 0.9807999730110168]\n"
     ]
    }
   ],
   "source": [
    "print(\"Base accuracy on regular images:\", model.evaluate(x=x_test, y=y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_pattern(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        prediction = model(image)\n",
    "        loss = tf.keras.losses.MSE(label, prediction)\n",
    "    \n",
    "    gradient = tape.gradient(loss, image)\n",
    "    \n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfWUlEQVR4nO3dfXCU9d3v8c9CyAISNoSQpxIwoELLk1MKkaoUJQeI97GgTI9Pf4DHgVETpkitTnpUtO05UZxajx4K9z13C/UeAfUegdG2nFE0YWwDBZTh0IcMyZ1KKEmotMlCMCEP1/mD221Xw8PvYne/m837NXPNkN3ru9c3v1ybD1d2803A8zxPAAAk2CDrBgAAAxMBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNp1g18Xm9vr06cOKGMjAwFAgHrdgAAjjzP0+nTp1VQUKBBgy58nZN0AXTixAkVFhZatwEAuEKNjY0aO3bsBe9PugDKyMiQJM0reEBpg9KNu7HVffyEdQsXN2uKe83+3yXmOH756S8VJXLNXfE1Oi+Jv0bdPZ364MMfRb6fX0jcAmj9+vV6/vnn1dzcrBkzZujll1/W7NmzL1n32Y/d0galK21QMF7t9Q+BIdYdXFzaUPcaP5+Tn+P4lexrniiJXHNXfI3OS+av0X+61MsocXkTwmuvvaY1a9Zo7dq1+vDDDzVjxgwtXLhQJ0+ejMfhAAD9UFwC6IUXXtCKFSt0//336ytf+Yo2btyo4cOH62c/+1k8DgcA6IdiHkDnzp3TwYMHVVJS8veDDBqkkpIS1dTUfGH/zs5OhcPhqA0AkPpiHkCffPKJenp6lJubG3V7bm6umpubv7B/ZWWlQqFQZOMdcAAwMJj/ImpFRYXa2toiW2Njo3VLAIAEiPm74LKzszV48GC1tLRE3d7S0qK8vLwv7B8MBhUMDvB3uwHAABTzK6D09HTNnDlTu3fvjtzW29ur3bt3a86cObE+HACgn4rL7wGtWbNGy5Yt09e+9jXNnj1bL774otrb23X//ffH43AAgH4oLgF011136S9/+YueeuopNTc36/rrr9euXbu+8MYEAMDAFbdJCOXl5SovL4/Xww8MN0x3r9l7OPZ9JMOxXCVzb/1BotbPzzmOlGH+LjgAwMBEAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARNyGkSIGGKh5XiLXIdkHwKYa1s4/v2uXiHPc67qs3bgCAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYBp2qkn2ac6J6s/PcfweC4AvXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwTDSZOZ3oGaiJKq/ZF8HPxL1OfkdrprM/SXyfEjUcNpEDhFOooG7XAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwkbTDSLvzR0lpQ+N7kCQaytenxuPWHVxcsq+fH4MGO5cMHp3lfpz6JvcaHz7+3td91fVcf9q55tynQ5xrvvznsc41gWf/4lxTmnPEuUaS/tZ9lXPN1m23OteMfe+Mc01CuQ5L7e6Q9u+85G5cAQEATBBAAAATMQ+gp59+WoFAIGqbPHlyrA8DAOjn4vIa0JQpU/Tuu+/+/SBpSftSEwDASFySIS0tTXl5efF4aABAiojLa0BHjx5VQUGBJkyYoPvuu0/Hjh274L6dnZ0Kh8NRGwAg9cU8gIqLi7V582bt2rVLGzZsUENDg26++WadPt332zorKysVCoUiW2FhYaxbAgAkoZgHUGlpqb71rW9p+vTpWrhwoX75y1+qtbVVr7/+ep/7V1RUqK2tLbI1NjbGuiUAQBKK+7sDMjMzdd1116murq7P+4PBoILBYLzbAAAkmbj/HtCZM2dUX1+v/Pz8eB8KANCPxDyAHn30UVVXV+tPf/qTfvOb3+iOO+7Q4MGDdc8998T6UACAfizmP4I7fvy47rnnHp06dUpjxozRTTfdpL1792rMmDGxPhQAoB+LeQBt27Yt1g85cLkOAJQSOiA0bcLVzjV/vcH998N60gPONaeu95xrJKk3o9u5pqH0X51rXv7beOcaP1aNesdXnZ/+alonuNc8M9G5Zs0Y98/pz52jnGsk6RcfT3GuSfvU16GSm+v3Fa/rsnZjFhwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATcf+DdL7t/50UGGLdRf/jZ4Bpr7/BnRv+fYNzzbi0Eb6OBX/8Dj3t8gY719T9y2TnmqFF7oNmt+0qda45O8bf/7WHtfU614Tqzvg6ljM/z3W/4jTkmCsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJ5J2GDX8TaH1MyO3MHup+HEm/PzfauWZcWqdzjd+JzomyatTHzjVne9Odaz7ucF/vgmCrc40kPZB5wLnm//58pHPNKOcK+TrHRxzzcyBEuK55d4e0f+cld+MKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgImBPYzUx1DDVBT85X5fdY987QHnmoeze5xrQrWDnWv++8O/cK7xa2Prl5xrqr6e51zTO6XIuaaho9u5RpJ+9exXnGtG6D98HQsJ5mfIsSuv67J24woIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAieQdRjpripQ21LoLW4kYGngFxn3/N841gzNDzjU9rW3ONS9eW+pcI0mr/8uvnGte2PFN55qi0zXONX7Oh16fA3dHPD3CV50zP/0l8nmRzP2lwDBlroAAACYIIACACecA2rNnj26//XYVFBQoEAhox44dUfd7nqennnpK+fn5GjZsmEpKSnT06NFY9QsASBHOAdTe3q4ZM2Zo/fr1fd6/bt06vfTSS9q4caP27dunq666SgsXLlRHR8cVNwsASB3Ob0IoLS1VaWnfL/B6nqcXX3xRTzzxhBYvXixJeuWVV5Sbm6sdO3bo7rvvvrJuAQApI6avATU0NKi5uVklJSWR20KhkIqLi1VT0/e7fjo7OxUOh6M2AEDqi2kANTc3S5Jyc3Ojbs/NzY3c93mVlZUKhUKRrbCwMJYtAQCSlPm74CoqKtTW1hbZGhsbrVsCACRATAMoLy9PktTS0hJ1e0tLS+S+zwsGgxo5cmTUBgBIfTENoKKiIuXl5Wn37t2R28LhsPbt26c5c+bE8lAAgH7O+V1wZ86cUV1dXeTjhoYGHTp0SFlZWRo3bpxWr16tH/7wh7r22mtVVFSkJ598UgUFBVqyZEks+wYA9HPOAXTgwAHdcsstkY/XrFkjSVq2bJk2b96sxx57TO3t7Vq5cqVaW1t10003adeuXRo6dIDPdQMARAl4nudZN/GPwuGwQqGQ5mmx0gJD4nuwZB/m52eoYTIPT0ygP/1Pfz/yrb1/g3PN4y3XO9d8VDbDuSbQm1RPVQwkjt8jur0uVWmn2traLvq6vvm74AAAAxMBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwITzn2NImFlTpDT+hIOzFJxs7WfC94Rnj/g61OO3Xe9c81zuIeeaeZmznGuCf+10rgFiwvU52N0h7d95yd24AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAieYeR7v+dFBhy+fv7GFiZ0MGdfvpL5uNI/tYvQf31nj7tq27Puhuca5qe+8C5puB/1DnX7D10nXONPPcSSbq2fJ+/QleJOl/9PtcT+XxKlER83/O6Lms3roAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYCHie53NcYXyEw2GFQiHN02KluQwj9SMVBw3ivAQOmj3zrWLnmn//0Y/ca05Pca7x6182/5Nzzbhtx5xruhuPO9fgCiVgcHO316Uq7VRbW5tGjhx5wf24AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAizbqBC5o1RUobevn7J3D4ZFLzsw6pOJTV7+fkY/1GvLHPueabI77rXBNe1O5cUz612rlGklYu/4Vzzf/OK3WumfRSwLmm++NG5xpcIdfnU3eHtH/nJXfjCggAYIIAAgCYcA6gPXv26Pbbb1dBQYECgYB27NgRdf/y5csVCASitkWLFsWqXwBAinAOoPb2ds2YMUPr16+/4D6LFi1SU1NTZNu6desVNQkASD3Ob0IoLS1VaenFX2wMBoPKy8vz3RQAIPXF5TWgqqoq5eTkaNKkSXrooYd06tSpC+7b2dmpcDgctQEAUl/MA2jRokV65ZVXtHv3bj333HOqrq5WaWmpenp6+ty/srJSoVAoshUWFsa6JQBAEor57wHdfffdkX9PmzZN06dP18SJE1VVVaX58+d/Yf+KigqtWbMm8nE4HCaEAGAAiPvbsCdMmKDs7GzV1dX1eX8wGNTIkSOjNgBA6ot7AB0/flynTp1Sfn5+vA8FAOhHnH8Ed+bMmairmYaGBh06dEhZWVnKysrSM888o6VLlyovL0/19fV67LHHdM0112jhwoUxbRwA0L85B9CBAwd0yy23RD7+7PWbZcuWacOGDTp8+LB+/vOfq7W1VQUFBVqwYIF+8IMfKBgMxq5rAEC/F/A8z7Nu4h+Fw2GFQiHNm/U9pbkMI01FDFj1L9kHrPr42g4eneVc88l/neRcI0n3PvYr55rVo/7kXPOdpq861xwpm+pc4xvPQV+6vS5Vaafa2tou+ro+s+AAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZi/ie5Y2b/76TAkPgeI9knJqciP2vuZyJxCk4x7jn1V+eaUbXtvo71UOZRH1Xuz9ec9NPONV0j3I8z5EyXc40kvkf41d0h7d95yd24AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAieYeRppoUHI7pS7KvQ4KGTwa6epxrjt0Wcq659ZsHnWskKRjvQcD/KTvNfRhp2tnuOHRyAcl8vqbAoFSugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgY2MNIk3nQYH+QAsMQP6/tmuHONV13/dW5ZvqYJueaf8o45lyzatTHzjWS9PLfxjvXPJj5H841B89c7VwT6PWca1Lyue73c0qi5y1XQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwM7GGkiRzKxzBE3z5dMtu5pu1qf6f2C6v+2blm/rAeX8dKBD9DRSWpRwHnmltXPexcM/zNfc41usG9hOf6FXL9nLyuy9qNKyAAgAkCCABgwimAKisrNWvWLGVkZCgnJ0dLlixRbW1t1D4dHR0qKyvT6NGjNWLECC1dulQtLS0xbRoA0P85BVB1dbXKysq0d+9evfPOO+rq6tKCBQvU3t4e2eeRRx7RW2+9pTfeeEPV1dU6ceKE7rzzzpg3DgDo35xeqd21a1fUx5s3b1ZOTo4OHjyouXPnqq2tTT/96U+1ZcsW3XrrrZKkTZs26ctf/rL27t2rG27w8+ohACAVXdFrQG1tbZKkrKwsSdLBgwfV1dWlkpKSyD6TJ0/WuHHjVFNT0+djdHZ2KhwOR20AgNTnO4B6e3u1evVq3XjjjZo6daokqbm5Wenp6crMzIzaNzc3V83NzX0+TmVlpUKhUGQrLCz02xIAoB/xHUBlZWU6cuSItm3bdkUNVFRUqK2tLbI1NjZe0eMBAPoHX7+tV15errffflt79uzR2LFjI7fn5eXp3Llzam1tjboKamlpUV5eXp+PFQwGFQwG/bQBAOjHnK6APM9TeXm5tm/frvfee09FRUVR98+cOVNDhgzR7t27I7fV1tbq2LFjmjNnTmw6BgCkBKcroLKyMm3ZskU7d+5URkZG5HWdUCikYcOGKRQK6YEHHtCaNWuUlZWlkSNHatWqVZozZw7vgAMARHEKoA0bNkiS5s2bF3X7pk2btHz5cknSj3/8Yw0aNEhLly5VZ2enFi5cqJ/85CcxaRYAkDqcAsjzvEvuM3ToUK1fv17r16/33ZQkadYUKW3olT0GLo/PQY1pjZ8415ydWuBcU77uNeealq5M5xopcYNF/QwJ3VTv/lOEYf+W6VwjSVf9ucO5ZvhvfAwWRf/g+j2iu0Pav/OSuzELDgBgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgwtdfRB3w9h627uCCOm+b5VyTXdHg61jdvYOda96/9l99HcvVy3/LTMhxJOmHn0x2rtn1/W841+T+8v851/SerXWuSXqJfP75mRTvpyaRn1MijuV1XdZuXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwkbzDSPf/TgoMufz9k3wA4MmHv+5c0/q1c841W+dtdK65Yaj7UNFk90n3CF91X/7nh51rCj7odK65avc+55pe54oE8/Mc9CPVBndKSf/9K164AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAieYeRzpoipQ217qJvPgYHfjrvtHNNw03/5lwjJW6w6LbTo5xr1h663blm0O/dB4sW/Z8/OtdI0rhrz/iqSzmpOFgUSYcrIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaSdxhpMvMxQHH8C+7DHRf+t+udaxLKx8DKqxM0fLInUcM0/WLY53mpuA7Jfu4lEa6AAAAmCCAAgAmnAKqsrNSsWbOUkZGhnJwcLVmyRLW1tVH7zJs3T4FAIGp78MEHY9o0AKD/cwqg6upqlZWVae/evXrnnXfU1dWlBQsWqL29PWq/FStWqKmpKbKtW7cupk0DAPo/pzch7Nq1K+rjzZs3KycnRwcPHtTcuXMjtw8fPlx5eXmx6RAAkJKu6DWgtrY2SVJWVlbU7a+++qqys7M1depUVVRU6OzZsxd8jM7OToXD4agNAJD6fL8Nu7e3V6tXr9aNN96oqVOnRm6/9957NX78eBUUFOjw4cN6/PHHVVtbqzfffLPPx6msrNQzzzzjtw0AQD/lO4DKysp05MgRffDBB1G3r1y5MvLvadOmKT8/X/Pnz1d9fb0mTpz4hcepqKjQmjVrIh+Hw2EVFhb6bQsA0E/4CqDy8nK9/fbb2rNnj8aOHXvRfYuLiyVJdXV1fQZQMBhUMBj00wYAoB9zCiDP87Rq1Spt375dVVVVKioqumTNoUOHJEn5+fm+GgQApCanACorK9OWLVu0c+dOZWRkqLm5WZIUCoU0bNgw1dfXa8uWLbrttts0evRoHT58WI888ojmzp2r6dMZTwEA+DunANqwYYOk879s+o82bdqk5cuXKz09Xe+++65efPFFtbe3q7CwUEuXLtUTTzwRs4YBAKnB+UdwF1NYWKjq6uoraggAMDAEvEulSoKFw2GFQiHN02KlBYbE92BMrYWVZJ9S7UcqTrbGeY5f2+7uDlXt/19qa2vTyJEjL7gfw0gBACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8P0nueNu1hQpbWh8j8FQwyvDMNfUxdc2sRK53kn0fY8rIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYSLpZcJ7nSZK6ezoTcLCu+B8jlXV3WHfQfyX7uZfMX9tkXzs/ErneftbPsb/Pvn9/9v38QgLepfZIsOPHj6uwsNC6DQDAFWpsbNTYsWMveH/SBVBvb69OnDihjIwMBQKBqPvC4bAKCwvV2NiokSNHGnVoj3U4j3U4j3U4j3U4LxnWwfM8nT59WgUFBRo06MKv9CTdj+AGDRp00cSUpJEjRw7oE+wzrMN5rMN5rMN5rMN51usQCoUuuQ9vQgAAmCCAAAAm+lUABYNBrV27VsFg0LoVU6zDeazDeazDeazDef1pHZLuTQgAgIGhX10BAQBSBwEEADBBAAEATBBAAAAT/SaA1q9fr6uvvlpDhw5VcXGxfvvb31q3lHBPP/20AoFA1DZ58mTrtuJuz549uv3221VQUKBAIKAdO3ZE3e95np566inl5+dr2LBhKikp0dGjR22ajaNLrcPy5cu/cH4sWrTIptk4qays1KxZs5SRkaGcnBwtWbJEtbW1Uft0dHSorKxMo0eP1ogRI7R06VK1tLQYdRwfl7MO8+bN+8L58OCDDxp13Ld+EUCvvfaa1qxZo7Vr1+rDDz/UjBkztHDhQp08edK6tYSbMmWKmpqaItsHH3xg3VLctbe3a8aMGVq/fn2f969bt04vvfSSNm7cqH379umqq67SwoUL1dGRxAM1fbjUOkjSokWLos6PrVu3JrDD+KuurlZZWZn27t2rd955R11dXVqwYIHa29sj+zzyyCN666239MYbb6i6ulonTpzQnXfeadh17F3OOkjSihUros6HdevWGXV8AV4/MHv2bK+srCzycU9Pj1dQUOBVVlYadpV4a9eu9WbMmGHdhilJ3vbt2yMf9/b2enl5ed7zzz8fua21tdULBoPe1q1bDTpMjM+vg+d53rJly7zFixeb9GPl5MmTniSvurra87zzX/shQ4Z4b7zxRmSfP/zhD54kr6amxqrNuPv8Onie533jG9/wvv3tb9s1dRmS/gro3LlzOnjwoEpKSiK3DRo0SCUlJaqpqTHszMbRo0dVUFCgCRMm6L777tOxY8esWzLV0NCg5ubmqPMjFAqpuLh4QJ4fVVVVysnJ0aRJk/TQQw/p1KlT1i3FVVtbmyQpKytLknTw4EF1dXVFnQ+TJ0/WuHHjUvp8+Pw6fObVV19Vdna2pk6dqoqKCp09e9aivQtKumGkn/fJJ5+op6dHubm5Ubfn5ubqj3/8o1FXNoqLi7V582ZNmjRJTU1NeuaZZ3TzzTfryJEjysjIsG7PRHNzsyT1eX58dt9AsWjRIt15550qKipSfX29vve976m0tFQ1NTUaPHiwdXsx19vbq9WrV+vGG2/U1KlTJZ0/H9LT05WZmRm1byqfD32tgyTde++9Gj9+vAoKCnT48GE9/vjjqq2t1ZtvvmnYbbSkDyD8XWlpaeTf06dPV3FxscaPH6/XX39dDzzwgGFnSAZ333135N/Tpk3T9OnTNXHiRFVVVWn+/PmGncVHWVmZjhw5MiBeB72YC63DypUrI/+eNm2a8vPzNX/+fNXX12vixImJbrNPSf8juOzsbA0ePPgL72JpaWlRXl6eUVfJITMzU9ddd53q6uqsWzHz2TnA+fFFEyZMUHZ2dkqeH+Xl5Xr77bf1/vvvR/35lry8PJ07d06tra1R+6fq+XChdehLcXGxJCXV+ZD0AZSenq6ZM2dq9+7dkdt6e3u1e/duzZkzx7Aze2fOnFF9fb3y8/OtWzFTVFSkvLy8qPMjHA5r3759A/78OH78uE6dOpVS54fneSovL9f27dv13nvvqaioKOr+mTNnasiQIVHnQ21trY4dO5ZS58Ol1qEvhw4dkqTkOh+s3wVxObZt2+YFg0Fv8+bN3u9//3tv5cqVXmZmptfc3GzdWkJ95zvf8aqqqryGhgbv17/+tVdSUuJlZ2d7J0+etG4trk6fPu199NFH3kcffeRJ8l544QXvo48+8j7++GPP8zzv2Wef9TIzM72dO3d6hw8f9hYvXuwVFRV5n376qXHnsXWxdTh9+rT36KOPejU1NV5DQ4P37rvvel/96le9a6+91uvo6LBuPWYeeughLxQKeVVVVV5TU1NkO3v2bGSfBx980Bs3bpz33nvveQcOHPDmzJnjzZkzx7Dr2LvUOtTV1Xnf//73vQMHDngNDQ3ezp07vQkTJnhz58417jxavwggz/O8l19+2Rs3bpyXnp7uzZ4929u7d691Swl31113efn5+V56err3pS99ybvrrru8uro667bi7v333/ckfWFbtmyZ53nn34r95JNPerm5uV4wGPTmz5/v1dbW2jYdBxdbh7Nnz3oLFizwxowZ4w0ZMsQbP368t2LFipT7T1pfn78kb9OmTZF9Pv30U+/hhx/2Ro0a5Q0fPty74447vKamJrum4+BS63Ds2DFv7ty5XlZWlhcMBr1rrrnG++53v+u1tbXZNv45/DkGAICJpH8NCACQmgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJj4//AJtRvI8nXnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating an Example Adversarial Image\n",
    "image = x_train[0]\n",
    "image_label = y_train[0]\n",
    "perturbations = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), image_label).numpy()\n",
    "adversarial = image + perturbations * 0.1\n",
    "if channels == 1:\n",
    "    plt.imshow(adversarial.reshape((img_rows, img_cols)))\n",
    "else:\n",
    "    plt.imshow(adversarial.reshape((img_rows, img_cols, channels)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "five\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "print(labels[model.predict(image.reshape((1, img_rows, img_cols, channels))).argmax()])\n",
    "print(labels[model.predict(adversarial).argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarials(batch_size):\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for batch in range(batch_size):\n",
    "            N = random.randint(0, 100)\n",
    "\n",
    "            label = y_train[N]\n",
    "            image = x_train[N]\n",
    "            \n",
    "            perturbations = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), label).numpy()\n",
    "            \n",
    "            \n",
    "            epsilon = 0.1\n",
    "            adversarial = image + perturbations * epsilon\n",
    "            \n",
    "            x.append(adversarial)\n",
    "            y.append(y_train[N])\n",
    "        \n",
    "        \n",
    "        x = np.asarray(x).reshape((batch_size, img_rows, img_cols, channels))\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy on adversarial images: [0.1501842588186264, 0.2003999948501587]\n"
     ]
    }
   ],
   "source": [
    "x_adversarial_test, y_adversarial_test = next(generate_adversarials(10000))\n",
    "print(\"Base accuracy on adversarial images:\", model.evaluate(x=x_adversarial_test, y=y_adversarial_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.0105 - accuracy: 0.9430 - val_loss: 0.0097 - val_accuracy: 0.9453\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.0028 - accuracy: 0.9853 - val_loss: 0.0102 - val_accuracy: 0.9431\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.0020 - accuracy: 0.9899 - val_loss: 0.0120 - val_accuracy: 0.9325\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.0019 - accuracy: 0.9902 - val_loss: 0.0118 - val_accuracy: 0.9347\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.0018 - accuracy: 0.9903 - val_loss: 0.0114 - val_accuracy: 0.9365\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 10s 15ms/step - loss: 9.8117e-05 - accuracy: 0.9993 - val_loss: 0.0116 - val_accuracy: 0.9359\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 6.3043e-05 - accuracy: 0.9997 - val_loss: 0.0119 - val_accuracy: 0.9347\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 1.0525e-04 - accuracy: 0.9994 - val_loss: 0.0138 - val_accuracy: 0.9242\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 9.5082e-05 - accuracy: 0.9995 - val_loss: 0.0177 - val_accuracy: 0.9053\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 1.8032e-04 - accuracy: 0.9988 - val_loss: 0.0158 - val_accuracy: 0.9142\n",
      "Defended accuracy on adversarial images: [1.5895861774823518e-21, 1.0]\n",
      "Defended accuracy on regular images: [0.01583571918308735, 0.9142000079154968]\n"
     ]
    }
   ],
   "source": [
    "x_adversarial_train, y_adversarial_train = next(generate_adversarials(20000))\n",
    "model.fit(x_adversarial_train, y_adversarial_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test))\n",
    "print(\"Defended accuracy on adversarial images:\", model.evaluate(x=x_adversarial_test, y=y_adversarial_test, verbose=0))\n",
    "print(\"Defended accuracy on regular images:\", model.evaluate(x=x_test, y=y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy on adversarial images: [0.02932284213602543, 0.8375999927520752]\n"
     ]
    }
   ],
   "source": [
    "x_adversarial_test, y_adversarial_test = next(generate_adversarials(10000))\n",
    "print(\"Base accuracy on adversarial images:\", model.evaluate(x=x_adversarial_test, y=y_adversarial_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
